(*  Title:      Pure/Concurrent/par_tree.ML    Author:     Michael James BradleyThis signature specifies a structure designed to help parallelise operations across trees.It is designed for lazy trees (trees which produce lazy sequences) although is applicably to anytree flow in the program. Trees should have many leaves, and the depth of the tree should be high.The structure will process elements of the tree, returning the leaves found in as in a preorder traversal (nodesare not returned).As should be obvious, if the tree is very left or right deep, evaluation will be inefficient as it will be forcedinto a sequential like process.It automatically parallelises the computation of the tree!Note: nodes are permitted to have zero childrenWarning: in the implementation there is a "node_limit" to prevent excessively large numbersof children ever being processed at once. However, if the tree is extremely large(or very right biased and a little smaller, but still large),it is possible for this process to run out of memory.*)signature PARALLEL_TREE =sig  (*Ths error is thrown when the parallel tree's functions are used incorrectly.  If the estimator within the parallel tree returns an estimate less than one, this will  also be thrown then.*)  exception Parallel_Tree_Use_Error of string    (*This is the type of returned elements  from the node function (keep reading for this to make sense)*)  datatype ('a,'b) elem = Node of 'b | Leaf of 'a    (*The type of a parallel tree!*)  type ('a,'b) ptree;    (*Create a new parallel tree. You must supply the future data that it  should use.*)  val new : Future_Wrapper.future_data (*Future data for the tree to use*)    -> ('a,'b) ptree      (*Get the future data in use by this parallel tree*)  val get_future_data : ('a,'b) ptree    -> Future_Wrapper.future_data    (*Set the number of groups of functions that should be created  during parallelisation. Only use this if you know how it works!  Essentially, groups taking the time specified within the compactor (below)  will be assigned to futures. The length is how many of these groups  should be created before assigning the tasks to cores. Typically,  10*the number of cores is a good way to overload the future's library.*)  val set_no_groups : ('a,'b) ptree    -> int option (*How many groups should be created for parallelisation.                    If NONE is supplied, it will use a default*)    -> ('a,'b) ptree    (*Return the number of groups to be created before parallelisation.  If nothing was set, it will return the default that it is going to use.    Default: no_cores * 40 *)  val get_no_groups : ('a,'b) ptree    -> int      (*Set the compactor used within the tree. There is a default compactor,  but it is a good idea to set this. The compactor is used  to form groups (mentioned above) of nodes in the tree to process in parallel.  Be aware that since this is entirely functional, you should set the parameters  of the compactor before you set within the tree.    IMPORTANT: the estimate for the number of functions to be combined into a group  to reach the desired time will be updated by the tree according to the compactor's  approximations as it procedes. Hence, your estimate will only be used once essentially*)  val set_compactor : ('a,'b) ptree      -> Compactor.compactor (*The compactor to use when parallelising groups*)      -> ('a,'b) ptree    (*Return the compactor used in this tree. If you ask for this without setting  the compactor, you will receive the default.    Default: prime length = 15           estimate = 1           go static = true           group time = 2000 microseconds  *)  val get_compactor : ('a,'b) ptree      -> Compactor.compactor    (*Set whether the order in which leaves are returned is important. Setting  this to false means that if a leaf is discovered in the tree  early (i.e: not the "first" one - leftmost) then the algorithm  can stop and return that. Hence, it is more likely to take less time  and memory when pulling leaves from the tree with this set to false.    Note that nodes are still computed in order, since it is generally  considered that leaves are more likely to appear deep in a tree.  Any advanced knowledge as to where leaves are likely to exist should be  used by the node function itself.  *)  val set_order_matters : ('a,'b) ptree    -> bool     (*True if the order of the leaves is important, or false otherwise*)    -> ('a,'b) ptree      (*Return whether or not the order the leaves are returned in is considered  important.    Default: true*)  val get_order_matters : ('a,'b) ptree    -> bool      (*Set the maximum number of nodes the algorithm is allowed to gather in the tree  before parallelisation. Passing NONE will ensure there is no limit at all. A limit  below 1 is not allowed. Typcially, a setting should be in the thousands. This can help  to prevent the algorithm running out of memory.*)  val set_node_limit : ('a,'b) ptree    -> int option (* NONE indicates that there should be no limit. Otherwise, the maximum                     number of nodes that may be gathered at one time. *)    -> ('a,'b) ptree      (*Return the current node limit in use by the tree.  Default: 16000*)  val get_node_limit : ('a,'b) ptree    -> int option      (*  This function allows you to set an estimator for the tree.  Default: NONE  Any estimates given will be supplied to the compactor on each pass. When this is NONE,  the last estimate of the compactor on the previous pass is supplied instead.    An estimator will estimate the number of nodes that need to be gathered into a group to run on a single core  for parallel computation.  The estimator is given:  (the previous sequence of nodes grouped for parallelisation,  the estimate that the compactor believes is now appropriate,  the sequence of children of the previous sequence of nodes after they were processed)    This is a little hard to explain.  1. The compactor will change its estimate of how many functions     need to be grouped together based on the time it is aiming for a group to take automatically. Hence,     the estimate supplied is the last estimate returned by the compactor.       2. The old nodes are the nodes that were fed to this compactor.    3. The children correspond to the next nodes that will be fed to     the compactor (so usually the children of the previously processed nodes).    An estimator should be fast, and is only worth setting if you have good knowledge about (chunks of) nodes which  are particularly hard to compute. Note that if there are some randomly very hard nodes to compute,  it may be worth trying to spread the work load within such nodes outside of the tree rather than try to  convince the compactor to consume only one of those into a group.    An intuitive use might be if, as the nodes become deeper, you know the workload increases sharply,  meaning the compactor will regularly put too many hard nodes into groups. This itself is only really  a problem if the compactor starts consuming the whole tree in very few groups,  but this can realistically happen. (You can augment your own nodes to include this depth parameter).  *)  val set_estimator : ('a,'b) ptree    -> (('b Seq.seq * int * 'b Seq.seq) -> int) option (*The estimator function*)    -> ('a,'b) ptree      (*Return the estimator in use by this tree*)  val get_estimator : ('a,'b) ptree    -> (('b Seq.seq * int * 'b Seq.seq) -> int) option    (*This function is the main work of the structure. It will evaluate the tree in a lazy way while parallelising  as much as possible.    Notes:  The function which returns a list of nodes or leaves can really change for each node if the node itself  holds the function to be applied too, so this is a very generic type signature    The node function permits nodes to have no children, so you can  avoid worrying about this case.  *)  val compute_tree : ('a,'b) ptree    -> ('a,'b) elem                         (*This is the root of the tree*)    -> ('b -> ((('a,'b) elem) List.list))   (*The function which, when applied to nodes, will produce their children*)    -> ('a Seq.seq)                         (*A resulting lazy sequence of leaves*)      (*Given a function to apply to nodes, convert this function to apply itself  to nodes recursively a fixed number of times. That is, recur_node_function f 2 would  cause f to be applied to a node, and then recursively it would be applied to all of the  children nodes. (For f 3, f would be applied to their children again)  The resulting list is the complete list of children from all the children  of the first node.    This is to increase the coarseness of parallelisation, although this technique could be  too naive for certain applications.*)  val recur_node_function :       ('b -> ((('a,'b) elem) List.list))   (*The original node function*)     -> int                                 (*The number of times to recur (must be >=1)*)     -> ('b -> ((('a,'b) elem) List.list))  (*A new node function which applies itself recursively the specified number of times*)  end;structure Parallel_Tree :> PARALLEL_TREE =struct  (*Ths error is thrown when the parallel tree's functions are used incorrectly.  If the estimator within the parallel tree returns an estimate less than one, this will  also be thrown then.*)  exception Parallel_Tree_Use_Error of string  local  (*Structures the parallel tree needs*)  structure Par_Seq = Safe_Parallel_Seq;    (*This is an implementation using difference lists! This  results in faster append - O(1). Laziness is not useful here, since the list  of child nodes must have been formulated by the function already.*)  structure Difference_List =  struct    (*The type of the difference list*)    datatype 'a difference_list = DList of ('a list -> 'a list)        (*Create a new empty difference list*)    val empty = DList (fn x => x)        (*Attach an element to the front of a difference list.    This is a little more expensive than an ordinary cons operation to a list*)    fun cons x (DList f) = DList (fn ls => x::(f ls))        (*Attach an element to the end of the list*)    fun snoc (DList f) x = DList (fn ls => (f (x::ls)))        (*Append one list to another. This is O(1) *)    fun append (DList f) (DList g) = DList (f o g)        (*Convert the contents of the difference list to a regular list*)    fun list_of (DList f) = f []        (*Convert from a list of values to a difference list with the same values*)    fun of_list [] = empty      | of_list (x::xs) = cons x (of_list xs)            (*Some local correctness tests*)    val _ = let      val ls = empty;      val _ = if ([]=(list_of ls)) then () else              raise ERROR "Difference list failure with empty";      val ls = cons 1 ls;      val _ = if ([1]=(list_of ls)) then () else              raise ERROR "Difference list failure with singleton";      val ls = cons 2 ls;      val _ = if ([2,1]=(list_of ls)) then () else              raise ERROR "Difference list failure with two";      val ls2 = cons 4 (cons 3 empty);      val new_ls = append ls ls2      val _ = if ([2,1,4,3]=(list_of new_ls)) then () else              raise ERROR "Difference list failure with append";      val res_ls = append (append (append (cons 1 empty) (append empty (append empty empty))) (append (cons 2 empty) (append empty (append empty empty)))) (cons 3 empty)      val _ = if ([1,2,3]=(list_of res_ls)) then () else              raise ERROR "Difference list failure with append 2";      in () end            end;    in  (*This is the type of returned elements  from the functions (keep reading for this to make sense)*)  datatype ('a,'b) elem = Node of 'b | Leaf of 'a    (*  IMPLEMENTATION FOR ESTIMATES:    The compactor with the parallel lazy sequence will be used to apply the function  over a sequence of nodes. The time aimed at is enough such that the compactor produces  a sufficiently large number of groups such that the parallel lazy sequence can make use of  these groups. this is quite a long time, so for small procedures, it is quite likely  that the entire tree will be consumed.    Tests suggest that a length of a minimum of (no.cores * 10) is close to optimal, but  longer is also close to optimal. Hence, this is the minimum target for the number  of nodes passed in.    The functions should take a minimum of about 1200 microseconds,  but a time of 20000 microseconds is recommended (per group) since  this keeps the estimates from the compactor more stable (stronger average).  The compactor will be left to figure out the how to group functions,  and its final estimate for the group size will  be passed back to it as an estimate for the next attempt. (If the compactor  is static, this is ignored)    The length of the resulting sequence will constantly be increased until the compactor  is producing enough groups. Hopefully this will be efficient enough.  *)  val recommended_time = Time.fromMicroseconds 2000; (*Number of microseconds for groups to aim for*)  fun num_cores() = Multithreading.max_threads_value();  fun recommended_length() = num_cores() * 40;  val recommended_prime_length = 15; (*How long the compactor should be allowed to run for*)  val recommended_est = 1; (*For the initial size of groups*)  val node_limit = 16000; (*This is a limit on the number of nodes that may be gathered*)  val order_matters = true; (*Safe as a default*)  (*The default compactor to use itself*)  val recommended_compactor = Compactor.prime (        Compactor.set_estimated_number (Compactor.new_dynamic recommended_time)        (*Let the compactor go static, because it will be used again*)        (SOME recommended_est)) (SOME recommended_prime_length) true;    (*The type of a parallel tree!  It remembers:  The compactor to use, the time to aim for, the number of groups which should  be created, the future data to use, and an estimate for the number  of functions.  The boolean value specifies if the order that leaves are returned  in is relevant  The next integer option is the node limit, if it exists.  The final entry is an estimator, which is supposed to enhance the initial esimated group  size by the compactor in case some knowledge of how hard nodes become is known (rarely not NONE  I would guess)*)  type ('a,'b) ptree = Compactor.compactor * int * Future_Wrapper.future_data * bool * (int option)                 * (('b Seq.seq * int * 'b Seq.seq) -> int) option    (*Create a new parallelising tree. You must supply the future data that it  should use.*)  fun new fd = (recommended_compactor,recommended_length(),fd,order_matters,SOME node_limit,NONE)    (*Get the future data in use by this parallel tree*)  fun get_future_data (_,_,fd,_,_,_) = fd    (*Set the number of groups of functions that should be created  during parallelisation. Only use this if you know how it works!  Essentially, groups taking the time specified above (set_time) to process  will be assigned to futures. The length is how many of these groups  should be created before assigning the tasks to cores. Typically,  10*the number of cores is a good way to overload the future's library.*)  fun set_no_groups (c,_,fd,ord,nlimit,estimator) l =    case l of        NONE => (c,recommended_length(),fd,ord,nlimit,estimator)      | SOME length => if (length<1) then      raise Parallel_Tree_Use_Error "Cannot create less than one group for parallelisation"      else (c,length,fd,ord,nlimit,estimator)      (*Return the number of groups to be created before parallelisation.  If nothing was set, it will return the default that it is going to use.*)  fun get_no_groups (_,l,_,_,_,_) = l    (*Set whether the order in which leaves are returned is important. Setting  this to false means that if a leaf is discovered in the tree  early (i.e: not the "first" one - leftmost) then the algorithm  can stop and return that. Hence, it is more likely to take less time  and memory when pulling leaves from the tree with this set to false.    Note that nodes are still computed in order, since it is generally  considered that leaves are more likely to appear deep in a tree.*)  fun set_order_matters (c,l,fd,_,nlimit,estimator) ord = (c,l,fd,ord,nlimit,estimator)    (*Return whether or not the order the leaves are returned in is considered  important*)  fun get_order_matters (_,_,_,ord,_,_) = ord    (*Set the maximum number of nodes the algorithm is allowed to gather in the tree  before parallelisation. Passing NONE will ensure there is no limit at all. A limit  below 1 is not allowed. Typcially, a setting should be in the thousands. This can help  to prevent the algorithm running out of memory.*)  fun set_node_limit (c,l,fd,ord,_,estimator) nlimit =    if (case nlimit of SOME v => (v<1) | NONE => false) then    raise Parallel_Tree_Use_Error "Cannot use a node limit less than one"    else (c,l,fd,ord,nlimit,estimator)      (*Return the current node limit in use by the tree.*)  fun get_node_limit (_,_,_,_,nlimit,_) =  nlimit    (*Set the compactor used within the tree. There is a default compactor,  but it is a good idea to set this. The compactor is used  to form groups (mentioned above) of nodes in the tree to process in parallel.  Be aware that since this is entirely functional, you should set the parameters  of the compactor BEFORE you set it to the tree.*)  fun set_compactor (_,l,fd,ord,nlimit,estimator) c = (c,l,fd,ord,nlimit,estimator)  (*Was not sure how to make this generic within a signature... Ideally, I'd make the  whole object a functor, but I feel the signature before the structure is really helpful.*)    (*Return the compactor used in this tree. If you ask for this without setting  the compactor, you will see the default.*)  fun get_compactor (c,_,_,_,_,_) = c    (*Set the estimator for the compactor to use*)  fun set_estimator (c,l,fd,ord,nlimit,_) estimator = (c,l,fd,ord,nlimit,estimator)      (*Return the estimator in use by this tree*)  fun get_estimator (_,_,_,_,_,estimator) = estimator    (*A complicated part of the algorithm is forming a sequence of unevaluated nodes, joined with sequences  of results. The sequence will consist of a dummy head and a dummy last element.*)    (*The type of a result. Points to another result to form a sequence*)  type 'a result = 'a Difference_List.difference_list  (*The type of an unevaluated element*)  datatype ('a,'b) tree_elem =                      (*Forms the head of the sequence. It only holds a list of results*)                      Dummy_Head of ('a list)                      (*This forms the end of the sequence, and does nothing...*)                    | Dummy_Tail                      (*The main part of the sequence. Results held are considered to be results obtained                      to the right of this node in the tree (so AFTER it). It holds the node it should evaluate*)                    | Not_Done of ('b * 'a result)  (*The type of a tree sequence*)  type ('a,'b) tree_seq = (('a,'b) tree_elem) Seq.seq  (*  The sequence evaluation works like this.  Upon pulling, see if the dummy head has any results to return. If so, return the result. If not,  it will compute an appropriate number of nodes. These nodes will return sequences of children, and the overall  result is a sequence of sequences of new nodes or results. These need to be reattached to the tree sequence.    This is done as follows. Firstly, when the unevaluated group is taken from the tree sequence, the tree sequence  is not modified. Hence, the sequence of sequences produced is in the same order as the sequence of unevaluated  elements in the tree sequence.    When encountering an element in the tree sequence, this will: pull from the sequence of sequences to get the next,  result. If:    (a) The children are all results, then the resulting elements will be stuck onto the previous unevaluated      element's results.  (b) If the children contain unevaluated elements, then the last unevaluated element will point to the next element      in the tree sequence. Similarly, the previous element in the tree sequence will be made to point to the first      unevaluated element in these children.  *)    fun add_to_tree_seq tr_sq cs  (*    (*The theoretical type signature...*)       ('a,'b) tree_seq (*The previous tree sequence*)    -> ((('a,'b) elem) List.list) Seq.seq (*The sequence of children*)    -> (('a,'b) tree_seq) (*The resulting tree sequence (with children replacing their parents)*)  *)  =    let      (*Converted from a sequence to a list, so this required a modification*)      fun add tree_sq child_sq =        case Seq.pull child_sq of            NONE => (tree_sq,Difference_List.empty)(*Must be finished*)          | SOME (children,child_sq) =>        (*Get the next tree element to replace...*)        case Seq.pull tree_sq of            (*Cannot happen...*)            NONE => raise ERROR "par_tree: Ran out of tree elements - semantic error"          | SOME (Dummy_Head _,_) => raise ERROR "par_tree: Pulled the head from the tree sequence - semantic error"          | SOME (Dummy_Tail,_) => raise ERROR "par_tree: Pulled the tail out of the sequence for modification - semantic error"          (*This is the node to replace!*)          | SOME (Not_Done (_,res),tq) =>            let              (*Get the results from the rest of the sequence first...*)              val (new_tree_sq,last_results) = add tq child_sq              (*Gather the first sequence of results...*)              fun first_res c_sq = case c_sq of                  [] => (c_sq,Difference_List.empty)                | ((Node _)::_) => (c_sq,Difference_List.empty) (*Finished gathering leaves*)                | ((Leaf v)::c_sq2) =>                  let                    val (sq2,res_sq) = first_res c_sq2                  in                    (sq2,Difference_List.cons v res_sq) (*Form the whole difference list of leaves*)                  end              (*First uneval is the first node found in the sequence after the leaves at the "front"              have been removed. First results are these leaves (leaves represent results)*)              val (first_uneval,first_results) = first_res children              (*Check if a sequence is empty...*)              fun seq_is_empty sq = case (Seq.pull sq) of                  NONE => true                | _ => false              (*Now start gathering recursively all of the results...*)              fun forge_seq c_sq =                case (c_sq) of                    [] => Seq.empty                  | ((Leaf _)::_) => raise ERROR                    "par_seq: should not be able to pull a leaf in forge_seq - semantic error"                  | ((Node n)::c_sq2) =>                let                  fun is_empty [] = true                    | is_empty _ = false;                  (*Gather the next continuous segment of leaves*)                  val (uneval,results) = first_res c_sq2                in                  (*The last one should have the old_results                  attached to the end...*)                  Seq.cons (Not_Done (n,                    if (is_empty uneval) then (Difference_List.append results (Difference_List.append res last_results))                    else results)) (forge_seq uneval)                end              (*This forms the new sequence to be inserted...*)              val to_insert = forge_seq first_uneval            in              (*Now insert the resulting sequence in! Append applies itself to each element              only once this way round*)              (Seq.append to_insert new_tree_sq,              if (seq_is_empty to_insert) then (*This was just a sequence of results...*)                Difference_List.append first_results (Difference_List.append res last_results) else first_results)            end    in      add tr_sq cs    end      (*This function computes all of a sequence of nodes...*)  fun compute_all_nodes nodes fd comp f =     let      (*Now parallelise over this sequence...      Each group produces a sequence of lists of children      Hence, the resulting sequence is a sequence of sequences of sequences!            Parallel lazy sequence used is the default. This seems to work well in practice,      but could be parameterised within the tree as well*)      val par_seq = (        Par_Seq.of_sequential_seq fd (        Compactor.compact_with_seq comp (        Seq.map (fn x => fn sq => Seq.cons (f x) sq) nodes) Seq.empty));    in      Par_Seq.sequential_seq_of (      Par_Seq.map (fn _ => fn (f,n) => (f(),n)) par_seq)    end    (*  tree_sq is the sequence of nodes and leaves  par_tree holds all of the parameterised data (node limit, group size etc)  old_nodes is the previous sequence of nodes to apply the function to  f is the function which, when applied to a node, will produce the children of  that node.    This function forms the overall sequence of leaves  *)  fun leaf_sequence tree_sq par_tree old_nodes est f = Seq.make (fn () => (    (*tree_sq must have a dummy head and tail*)    case (Seq.pull tree_sq) of        NONE => raise ERROR "par_tree: missing the dummy head"      | SOME (Dummy_Tail,_) => raise ERROR "par_tree: pulled dummy tail by accident"      | SOME (Not_Done _,_) => raise ERROR "par_tree: pulled node by accident"      | SOME (Dummy_Head leaves,tr_sq) => case (leaves) of          (leaf::rest_of_leaves) =>          SOME (leaf,leaf_sequence (Seq.cons (Dummy_Head rest_of_leaves) tr_sq) par_tree old_nodes est f)        | [] => (*The hard case... No more leaves in the dummy head*)          case (Seq.pull tr_sq) of            SOME (Dummy_Tail,_) => (*Finished*) NONE          | _ =>          let            (*Convert the tree sequence into a sequence containing just the nodes*)            fun to_nodes sq = Seq.make (fn () => case (Seq.pull sq) of                SOME (Dummy_Tail,_) => NONE              | SOME (Dummy_Head _,_) => raise ERROR "par_tree: pulled head while returning nodes"              | SOME (Not_Done (v,_),sq2) => SOME (v,to_nodes sq2)              | NONE => raise ERROR "par_tree: reached end of sequence without seeing tail");            (*Get the estimate for the number of nodes we should gather*)            val est = case (get_estimator par_tree) of                NONE => est              | SOME f => f (old_nodes,est,to_nodes tree_sq);            val _ = if (est<1) then              raise Parallel_Tree_Use_Error "The estimator within the parallel tree returned an estimate less than one"              else ();            (*The number of nodes we will gather*)            val to_gather = (((est : LargeInt.int)*((get_no_groups par_tree) : LargeInt.int)) : LargeInt.int);            val to_gather = case (get_node_limit par_tree) of              NONE => to_gather            | SOME n => if (to_gather>n) then n else to_gather; (*Limit*)            fun gather (0 : LargeInt.int) _ = Seq.empty              | gather n sq = case (Seq.pull sq) of                  SOME (Dummy_Tail,_) => Seq.empty (*finished*)                | SOME (Dummy_Head _,_) => raise ERROR "par_tree: pulled head while gathering nodes"                | SOME (Not_Done (v,_),sq2) => Seq.cons v (gather (n-(1 : LargeInt.int)) sq2)                | NONE => raise ERROR "par_tree: reached end of sequence without seeing tail";            (*Now compute the sequence of children...*)            val nodes = gather to_gather tr_sq; (*Avoid feeding the head*)            (*The compactor to use...*)            val comp = get_compactor par_tree;            val comp = if (Compactor.is_dynamic comp) then Compactor.set_estimated_number comp (SOME est)              else comp;            val fd = get_future_data par_tree;            (*Now parallelise over this sequence...            Each group produces a sequence of sequences of children            Hence, the resulting sequence is a sequence of sequences of sequences!*)            val result = compute_all_nodes nodes fd comp f;            (*Check the final estimate and flatten the results*)            fun get_est sq = case (Seq.pull sq) of                NONE => (Seq.empty,~1)              | SOME ((v,n),sq2) => let                val (res_sq,res_est) = get_est sq2              in (Seq.append v res_sq, (*Flattening*)                  if (res_est>=0) then res_est else n) end;            val (children,new_est) = get_est result;            (*Now combine all of the results...*)            val (new_tree_sq,extra_leaves) = add_to_tree_seq tr_sq children;            val new_tree_sq = Seq.cons (Dummy_Head (Difference_List.list_of extra_leaves)) new_tree_sq          in            (*Recur now on the rest*)            Seq.pull (leaf_sequence new_tree_sq par_tree nodes new_est f)          end))    (*********************************************************************************)  (*This part of the algorithm is for when the order of the leaves does not matter  For efficiency, it is reimplemented since many of the complexities of the previous  algorithm can be avoided (ordering the leaves and storing them by nodes)*)  (*********************************************************************************)    (*This is the datatype to hold all of the nodes together!  The computed leaves are in the first argument. The nodes to be  computed appear, in order, in the second*)  type ('a,'b) node_list = ('a List.list * 'b List.list)    (*Compute the sequence.  n_list = the node list of the form above  par_tree holds all of the tree's parameters  old_nodes is for the estimator, and remembers which nodes were computed  est is the previous estimate from the compactor  f is the function which, when applied to nodes, produces their children*)  fun leaf_sequence_without_order n_list par_tree old_nodes est f = Seq.make (fn() =>    case (n_list) of      ([],[]) => NONE (*Must be done*)    | (leaf::leaves,nodes) => SOME (leaf, leaf_sequence_without_order (leaves,nodes) par_tree old_nodes est f)    | ([],nodes) => (*The hard case... There are no more leaves to return*)      let        (*Figure out the estimate for the nodes...*)        val est = case (get_estimator par_tree) of            NONE => est          | SOME f => f (old_nodes,est,Seq.of_list nodes);        val _ = if (est<1) then          raise Parallel_Tree_Use_Error "The estimator within the parallel tree returned an estimate less than one"          else ();        (*How many nodes to combine together...*)        val to_gather = (((est : LargeInt.int)*((get_no_groups par_tree) : LargeInt.int)) : LargeInt.int);        val to_gather = case (get_node_limit par_tree) of            NONE => to_gather          | SOME n => if (to_gather>n) then n else to_gather; (*Limit*)        (*Now divide the list into its two halves...nodes to be        computed and those left alone*)        fun divide 0 xs = ([],xs)          | divide _ [] = ([],[])          | divide n (x::xs) = let val (h1,h2) = divide (n-1) xs in              (x::h1,h2)            end;        (*Now the two halves*)        val (nodes_to_compute,kept_nodes) = divide to_gather nodes;        (*The compactor to use... Uses the previous estimate to guess this one*)        val comp = get_compactor par_tree;        val comp = if (Compactor.is_dynamic comp) then Compactor.set_estimated_number comp (SOME est)                   else comp;        val fd = get_future_data par_tree;        val nodes_to_compute_seq = Seq.of_list nodes_to_compute;        val result = compute_all_nodes nodes_to_compute_seq fd comp f;        (*Check the final estimate and flatten the results*)        fun get_est sq = case (Seq.pull sq) of            NONE => ([],~1) (*Guaranteed to be at least one element*)          | SOME ((v,n),sq2) => let                   val (res_sq,res_est) = get_est sq2          in ((Seq.list_of v)@res_sq,if (res_est>=0) then res_est else n) end;        (*The children are the resulting mix of leaves and nodes, currently        in the order they were produced*)        val (children,new_est) = get_est result;        (*Next, split this up into nodes and leaves...*)        fun find_leaves [] = ([],[])          | find_leaves (c::cs) = let val (leaves,nodes) = find_leaves cs in            case c of              Leaf l => (l::leaves,nodes)            | Node n => (leaves,n::nodes)          end;        (*The new leaves, and the new nodes*)        val (new_leaves,new_nodes) = find_leaves (flat children);        (*Construct the new list of nodes...*)        val new_nodes = new_nodes@kept_nodes;        (*Now see if we have anything to return...*)      in        case new_leaves of          [] => (*Still no leaves found...*)            Seq.pull (leaf_sequence_without_order ([],new_nodes) par_tree nodes_to_compute_seq new_est f)        | (l::ls) => (*Leaves!! Return the first one...*)            SOME (l,leaf_sequence_without_order (ls,new_nodes) par_tree nodes_to_compute_seq new_est f)      end)            (*This function is the main work of the structure. It will evaluate the tree in a lazy way while parallelising  as much as possible.    Notes:  The function which returns a list of nodes or leaves can really change for each node if the node itself  holds the function to be applied too, so this is a very generic type signature    The node function permits nodes to have no children, so you can  avoid worrying about this case.  *)  fun compute_tree par_tree root f =      let        val c = get_compactor par_tree;        val est = if (Compactor.is_static c) then            Compactor.get_size c          else            case (Compactor.get_estimated_number c) of                NONE => recommended_est (*the default here may differ from the compactor's*)              | (SOME e) => e      in        case root of          Leaf v => Seq.single v (*Special case*)        | Node v => (*Decide which algorithm to use based on whether or                    not the order matters*)                    if (get_order_matters par_tree) then (                      (*Setup...*)                      leaf_sequence (Seq.cons (Dummy_Head [])                      (Seq.cons (Not_Done (v,Difference_List.empty))                       (Seq.single Dummy_Tail))) par_tree Seq.empty est f                    ) else (                      (*Use this specialised version to work more quickly when the order is irrelevant*)                      leaf_sequence_without_order ([],[v]) par_tree Seq.empty est f                    )      end    (*Given a function to apply to nodes, convert this function to apply itself  to nodes recursively a fixed number of times. That is, recur_node_function f 2 would  cause f to be applied to a node, and then recursively it would be applied to all of the  children nodes. (For f 3, f would be applied to their children again)  The resulting list is the complete list of children from all the children  of the first node.*)  fun recur_node_function f depth = if (depth<=0) then raise Parallel_Tree_Use_Error "Cannot recur a node function less than one time" else    if (depth=1) then f else    let      (*Apply the node function recursively to the nodes, their children, their children's children etc...*)      fun apply_to_node_recur 0 node = Difference_List.of_list (f node) (*Stop the recursion*)        | apply_to_node_recur n node =          let           val res = f node;           (*Apply the node function to nay leaves it finds...*)           fun map_apply [] = Difference_List.empty             | map_apply ((Leaf l)::ns) = Difference_List.cons (Leaf l) (map_apply ns)             | map_apply ((Node nd)::ns) = Difference_List.append (apply_to_node_recur (n-1) nd) (map_apply ns)          in            map_apply res          end    in      (*Compute the nodes to the specified depth (-1 is necessary due to the implementation*)      (fn node => Difference_List.list_of (apply_to_node_recur (depth-1) node))    end    endend;